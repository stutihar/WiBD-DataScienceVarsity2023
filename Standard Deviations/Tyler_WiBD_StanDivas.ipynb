{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "514da52b-c230-413a-a431-fcfb4c220501",
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.utils import column_or_1d\n",
    "import os\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "from sklearn.model_selection import cross_val_score\n",
    "import re\n",
    "import time as t\n",
    "\n",
    "#data = pd.read_csv('training_set_features (1).csv', 'training_set_labels (1).csv', 'test_set_features (1).csv')\n",
    "notebook_path = os.path.abspath(\"\") + '/'\n",
    "\n",
    "data = pd.read_csv(notebook_path + 'training_set_features (1).csv')\n",
    "labels = pd.read_csv(notebook_path + 'training_set_labels (1).csv')\n",
    "test = pd.read_csv(notebook_path + 'test_set_features (1).csv')\n",
    "feature_list = []\n",
    "\n",
    "class CustomOrderLabelEncoder(LabelEncoder):\n",
    "  def fit(self, y):\n",
    "    y = column_or_1d(y, warn=True)\n",
    "    self.classes_ = pd.Series(y).unique()\n",
    "    return self\n",
    "\n",
    "data.count()\n",
    "\n",
    "data.values\n",
    "\n",
    "for (columnName, columnData) in data.items():\n",
    "    print('Column Name : ', columnName, columnData.dtype)\n",
    "    print('Unique Contents : ', columnData.unique(), \"\\n\")\n",
    "\n",
    "le_age_group = CustomOrderLabelEncoder()\n",
    "\n",
    "le_age_group.fit(['18 - 34 Years', '35 - 44 Years', '45 - 54 Years', '55 - 64 Years', '65+ Years'])\n",
    "\n",
    " \n",
    "\n",
    "data['enc_age_group'] = le_age_group.transform(data['age_group'])\n",
    "if 'enc_age_group' not in feature_list:\n",
    "    feature_list.append('enc_age_group')\n",
    "\n",
    " \n",
    "\n",
    "data.loc[1:10, ['enc_age_group', 'age_group']]\n",
    "\n",
    "le_education = CustomOrderLabelEncoder()\n",
    "\n",
    "le_education.fit(['< 12 Years', '12 Years', 'Some College', 'College Graduate'])\n",
    "\n",
    " \n",
    "\n",
    "data['enc_education'] = pd.Series(\n",
    "\n",
    "    le_education.transform(data['education'][data['education'].notnull()]),\n",
    "\n",
    "    index=data['education'][data['education'].notnull()].index\n",
    "\n",
    ")\n",
    "if 'enc_education' not in feature_list:\n",
    "    feature_list.append('enc_education')\n",
    "\n",
    " \n",
    "\n",
    "data.loc[1:10, ['enc_education', 'education']]\n",
    "\n",
    "le_income_poverty = CustomOrderLabelEncoder()\n",
    "\n",
    "le_income_poverty.fit(['Below Poverty', '<= $75,000, Above Poverty', '> $75,000'])\n",
    "\n",
    " \n",
    "\n",
    "data['enc_income_poverty'] = pd.Series(\n",
    "    \n",
    "    le_income_poverty.transform(data['income_poverty'][data['income_poverty'].notnull()]),\n",
    "    \n",
    "    index=data['income_poverty'][data['income_poverty'].notnull()].index\n",
    "               \n",
    ")\n",
    "if 'enc_income_poverty' not in feature_list:\n",
    "    feature_list.append('enc_income_poverty')\n",
    " \n",
    "\n",
    "data.loc[1:10, ['enc_income_poverty', 'income_poverty']]\n",
    "\n",
    "# define One_Hot(prefix, x, y, z= 'blah'):\n",
    "\n",
    "data = data.drop(columns=['race_White', 'race_Black', 'race_Other or Multiple', 'race_Hispanic'], errors='ignore')\n",
    "\n",
    "data = pd.concat([data, pd.get_dummies(data.race, prefix='race')], axis=1)\n",
    "\n",
    " \n",
    "\n",
    "data.loc[4107:4111, ['race', 'race_White', 'race_Black', 'race_Other or Multiple', 'race_Hispanic']]\n",
    "column_list = list(data)\n",
    "pattern = re.compile(r'^race_(?!.*_nan$).*')\n",
    "column_list =  list(filter(pattern.match, column_list))\n",
    "for x in column_list: \n",
    "    if x not in feature_list: feature_list.append(x)\n",
    "print (column_list) \n",
    "\n",
    "le_sex = CustomOrderLabelEncoder()\n",
    "\n",
    "le_sex.fit(['Female', 'Male'])\n",
    "\n",
    " \n",
    "\n",
    "data['enc_sex'] = pd.Series(\n",
    "    \n",
    "    le_sex.transform(data['sex'][data['sex'].notnull()]),\n",
    "    \n",
    "    index=data['sex'][data['sex'].notnull()].index\n",
    "               \n",
    ")\n",
    "if 'enc_sex' not in feature_list:\n",
    "    feature_list.append('enc_sex')\n",
    " \n",
    "\n",
    "data.loc[1:10, ['enc_sex', 'sex']]\n",
    "\n",
    "le_marital_status = CustomOrderLabelEncoder()\n",
    "\n",
    "le_marital_status.fit(['Not Married', 'Married'])\n",
    "\n",
    " \n",
    "\n",
    "data['enc_marital_status'] = pd.Series(\n",
    "    \n",
    "    le_marital_status.transform(data['marital_status'][data['marital_status'].notnull()]),\n",
    "    \n",
    "    index=data['marital_status'][data['marital_status'].notnull()].index\n",
    "               \n",
    ")\n",
    "if 'enc_marital_status' not in feature_list:\n",
    "    feature_list.append('enc_marital_status')\n",
    " \n",
    "\n",
    "data.loc[1:10, ['enc_marital_status', 'marital_status']]\n",
    "\n",
    "le_rent_or_own = CustomOrderLabelEncoder()\n",
    "\n",
    "le_rent_or_own.fit(['Own', 'Rent'])\n",
    "\n",
    " \n",
    "\n",
    "data['enc_rent_or_own'] = pd.Series(\n",
    "    \n",
    "    le_rent_or_own.transform(data['rent_or_own'][data['rent_or_own'].notnull()]),\n",
    "    \n",
    "    index=data['rent_or_own'][data['rent_or_own'].notnull()].index\n",
    "               \n",
    ")\n",
    "if 'enc_rent_or_own' not in feature_list:\n",
    "    feature_list.append('enc_rent_or_own')\n",
    " \n",
    "\n",
    "data.loc[1:10, ['enc_rent_or_own', 'rent_or_own']]\n",
    "\n",
    "le_employment_status = CustomOrderLabelEncoder()\n",
    "\n",
    "le_employment_status.fit(['Not in Labor Force', 'Employed', 'Unemployed'])\n",
    "\n",
    " \n",
    "\n",
    "data['enc_employment_status'] = pd.Series(\n",
    "    \n",
    "    le_employment_status.transform(data['employment_status'][data['employment_status'].notnull()]),\n",
    "    \n",
    "    index=data['employment_status'][data['employment_status'].notnull()].index\n",
    "               \n",
    ")\n",
    "if 'enc_employment_staus' not in feature_list:\n",
    "    feature_list.append('enc_employment_status')\n",
    " \n",
    "\n",
    "data.loc[1:10, ['enc_employment_status', 'employment_status']]\n",
    "\n",
    "data = data.drop(columns=['region_oxchjgsf', 'region_bhuqouqj', 'region_qufhixun', 'region_lrircsnp', 'region_atmpeygn', 'region_lzgpxyit',\n",
    " 'region_fpwskwrf', 'region_mlyzmhmf', 'region_dqpwygqj', 'region_kbazzjca'], errors='ignore')\n",
    "\n",
    "data = pd.concat([data, pd.get_dummies(data.hhs_geo_region, prefix='region')], axis=1)\n",
    "\n",
    " \n",
    "\n",
    "data.loc[4107:4111, ['hhs_geo_region', 'region_oxchjgsf', 'region_bhuqouqj', 'region_qufhixun', 'region_lrircsnp', 'region_atmpeygn', 'region_lzgpxyit',\n",
    " 'region_fpwskwrf', 'region_mlyzmhmf', 'region_dqpwygqj', 'region_kbazzjca']]\n",
    "column_list = list(data)\n",
    "pattern = re.compile(r'^region_(?!.*_nan$).*')\n",
    "column_list =  list(filter(pattern.match, column_list))\n",
    "for x in column_list: \n",
    "    if x not in feature_list: feature_list.append(x)\n",
    "print (column_list) \n",
    "\n",
    "data = data.drop(columns=['msa_Non-MSA', 'msa_MSA, Not Principle  City', 'msa_MSA, Principle City'], errors='ignore')\n",
    "\n",
    "data = pd.concat([data, pd.get_dummies(data.census_msa, prefix='msa')], axis=1)\n",
    "\n",
    " \n",
    "\n",
    "data.loc[4107:4111, ['census_msa', 'msa_Non-MSA', 'msa_MSA, Not Principle  City', 'msa_MSA, Principle City']]\n",
    "column_list = list(data)\n",
    "pattern = re.compile(r'^msa_(?!.*_nan$).*')\n",
    "column_list =  list(filter(pattern.match, column_list))\n",
    "for x in column_list: \n",
    "    if x not in feature_list: feature_list.append(x)\n",
    "print (column_list) \n",
    "\n",
    "data = data.drop(columns=['pxcmvdjn', 'rucpziij', 'wxleyezf', 'saaquncn', 'xicduogh', 'ldnlellj',\n",
    " 'wlfvacwt', 'nduyfdeo', 'fcxhlnwr', 'vjjrobsf', 'arjwrbjb', 'atmlpfrs',\n",
    " 'msuufmds', 'xqicxuve', 'phxvnwax', 'dotnnunm', 'mfikgejo', 'cfqqtusy',\n",
    " 'mcubkhph', 'haxffmxo', 'qnlwzans'], errors='ignore')\n",
    "\n",
    "data = pd.concat([data, pd.get_dummies(data.employment_industry, prefix='industry')], axis=1)\n",
    " \n",
    "\n",
    "data.loc[4107:4111, ['employment_industry', 'industry_pxcmvdjn', 'industry_rucpziij', 'industry_wxleyezf', 'industry_saaquncn', 'industry_xicduogh', 'industry_ldnlellj',\n",
    " 'industry_wlfvacwt', 'industry_nduyfdeo', 'industry_fcxhlnwr', 'industry_vjjrobsf', 'industry_arjwrbjb', 'industry_atmlpfrs',\n",
    " 'industry_msuufmds', 'industry_xqicxuve', 'industry_phxvnwax', 'industry_dotnnunm', 'industry_mfikgejo', 'industry_cfqqtusy',\n",
    " 'industry_mcubkhph', 'industry_haxffmxo', 'industry_qnlwzans']]\n",
    "column_list = list(data)\n",
    "pattern = re.compile(r'^industry_(?!.*_nan$).*')\n",
    "column_list =  list(filter(pattern.match, column_list))\n",
    "for x in column_list: \n",
    "    if x not in feature_list: feature_list.append(x)\n",
    "print (column_list) \n",
    "\n",
    "data = data.drop(columns=['xgwztkwe', 'xtkaffoo', 'emcorrxb', 'vlluhbov', 'xqwwgdyp', 'ccgxvspp',\n",
    " 'qxajmpny', 'kldqjyjy', 'mxkfnird', 'hfxkjkmi', 'bxpfxfdn', 'ukymxvdu',\n",
    " 'cmhcxjea', 'haliazsg', 'dlvbwzss', 'xzmlyyjv', 'oijqvulv', 'rcertsgn',\n",
    " 'tfqavkke', 'hodpvpew', 'uqqtjvyb', 'pvmttkik', 'dcjcmpih'], errors='ignore')\n",
    "\n",
    "data = pd.concat([data, pd.get_dummies(data.employment_occupation, prefix='occupation')], axis=1)\n",
    "\n",
    " \n",
    "\n",
    "data.loc[4107:4111, ['employment_occupation', 'occupation_xgwztkwe', 'occupation_xtkaffoo', 'occupation_emcorrxb', 'occupation_vlluhbov', 'occupation_xqwwgdyp', 'occupation_ccgxvspp',\n",
    " 'occupation_qxajmpny', 'occupation_kldqjyjy', 'occupation_mxkfnird', 'occupation_hfxkjkmi', 'occupation_bxpfxfdn', 'occupation_ukymxvdu',\n",
    " 'occupation_cmhcxjea', 'occupation_haliazsg', 'occupation_dlvbwzss', 'occupation_xzmlyyjv', 'occupation_oijqvulv', 'occupation_rcertsgn',\n",
    " 'occupation_tfqavkke', 'occupation_hodpvpew', 'occupation_uqqtjvyb', 'occupation_pvmttkik', 'occupation_dcjcmpih']]\n",
    "column_list = list(data)\n",
    "pattern = re.compile(r'^occupation_(?!.*_nan$).*')\n",
    "column_list =  list(filter(pattern.match, column_list))\n",
    "for x in column_list: \n",
    "    if x not in feature_list: feature_list.append(x)\n",
    "print (column_list) \n",
    "\n",
    "# Changed List to Numeric_List\n",
    "# Do we need to do somehting with this for the test data frame as well?\n",
    "\n",
    "numeric_lists = ['h1n1_concern','h1n1_knowledge','behavioral_antiviral_meds','behavioral_avoidance',\n",
    "         'behavioral_face_mask','behavioral_wash_hands','behavioral_large_gatherings','behavioral_outside_home',\n",
    "         'behavioral_touch_face','doctor_recc_h1n1','doctor_recc_seasonal','chronic_med_condition','child_under_6_months',\n",
    "         'health_worker','health_insurance','opinion_h1n1_vacc_effective','opinion_h1n1_risk','opinion_h1n1_sick_from_vacc',\n",
    "         'opinion_seas_vacc_effective','opinion_seas_risk','opinion_seas_sick_from_vacc','household_adults','household_children'] \n",
    "for x in numeric_lists: \n",
    "    if x not in feature_list: feature_list.append(x)\n",
    "print (feature_list)\n",
    "\n",
    "\n",
    "features = data.get(feature_list)\n",
    "\n",
    "print (features.count())\n",
    "\n",
    "mean_features = data.dropna().mean(numeric_only=True)\n",
    "\n",
    "imputed_features = data.fillna(mean_features)\n",
    "\n",
    "with pd.option_context('display.max_rows', None, 'display.max_columns', None):\n",
    "\n",
    "    print(imputed_features.count())\n",
    "\n",
    "\n",
    "rf = RandomForestClassifier (n_estimators=300)\n",
    "\n",
    "rf_scores = cross_val_score(rf, imputed_features.get(feature_list), labels['h1n1_vaccine'], cv=10, n_jobs=4, scoring= 'roc_auc')\n",
    "\n",
    "print('h1n1', rf_scores.min(), rf_scores.mean(), rf_scores.max())\n",
    "\n",
    "rf_scores = cross_val_score(rf, imputed_features.get(feature_list), labels['seasonal_vaccine'], cv=10, n_jobs=4, scoring= 'roc_auc')\n",
    "\n",
    "print('seas', rf_scores.min(), rf_scores.mean(), rf_scores.max())\n",
    "\n",
    "gb = GradientBoostingClassifier (n_estimators=300)\n",
    "\n",
    "gb_scores = cross_val_score(gb, imputed_features.get(feature_list), labels['h1n1_vaccine'], cv=10, n_jobs=4, scoring= 'roc_auc')\n",
    "\n",
    "print('h1n1', gb_scores.min(), gb_scores.mean(), gb_scores.max())\n",
    "\n",
    "gb_scores = cross_val_score(gb, imputed_features.get(feature_list), labels['seasonal_vaccine'], cv=10, n_jobs=4, scoring= 'roc_auc')\n",
    "\n",
    "print('seas', gb_scores.min(), gb_scores.mean(), gb_scores.max())\n",
    "\n",
    "le_age_group = CustomOrderLabelEncoder()\n",
    "\n",
    "le_age_group.fit(['18 - 34 Years', '35 - 44 Years', '45 - 54 Years', '55 - 64 Years', '65+ Years'])\n",
    "\n",
    " \n",
    "\n",
    "test['enc_age_group'] = le_age_group.transform(test['age_group'])\n",
    "if 'enc_age_group' not in feature_list:\n",
    "    feature_list.append('enc_age_group')\n",
    "\n",
    " \n",
    "\n",
    "test.loc[1:10, ['enc_age_group', 'age_group']]\n",
    "\n",
    "le_education = CustomOrderLabelEncoder()\n",
    "\n",
    "le_education.fit(['< 12 Years', '12 Years', 'Some College', 'College Graduate'])\n",
    "\n",
    " \n",
    "\n",
    "test['enc_education'] = pd.Series(\n",
    "\n",
    "    le_education.transform(test['education'][test['education'].notnull()]),\n",
    "\n",
    "    index=test['education'][test['education'].notnull()].index\n",
    "\n",
    ")\n",
    "if 'enc_education' not in feature_list:\n",
    "    feature_list.append('enc_education')\n",
    "\n",
    " \n",
    "\n",
    "test.loc[1:10, ['enc_education', 'education']]\n",
    "\n",
    "le_income_poverty = CustomOrderLabelEncoder()\n",
    "\n",
    "le_income_poverty.fit(['Below Poverty', '<= $75,000, Above Poverty', '> $75,000'])\n",
    "\n",
    " \n",
    "\n",
    "test['enc_income_poverty'] = pd.Series(\n",
    "    \n",
    "    le_income_poverty.transform(test['income_poverty'][test['income_poverty'].notnull()]),\n",
    "    \n",
    "    index=test['income_poverty'][test['income_poverty'].notnull()].index\n",
    "               \n",
    ")\n",
    "if 'enc_income_poverty' not in feature_list:\n",
    "    feature_list.append('enc_income_poverty')\n",
    " \n",
    "\n",
    "test.loc[1:10, ['enc_income_poverty', 'income_poverty']]\n",
    "\n",
    "le_sex = CustomOrderLabelEncoder()\n",
    "\n",
    "le_sex.fit(['Female', 'Male'])\n",
    "\n",
    " \n",
    "\n",
    "test['enc_sex'] = pd.Series(\n",
    "    \n",
    "    le_sex.transform(test['sex'][test['sex'].notnull()]),\n",
    "    \n",
    "    index=test['sex'][test['sex'].notnull()].index\n",
    "               \n",
    ")\n",
    "if 'enc_sex' not in feature_list:\n",
    "    feature_list.append('enc_sex')\n",
    " \n",
    "\n",
    "test.loc[1:10, ['enc_sex', 'sex']]\n",
    "\n",
    "le_marital_status = CustomOrderLabelEncoder()\n",
    "\n",
    "le_marital_status.fit(['Not Married', 'Married'])\n",
    "\n",
    " \n",
    "\n",
    "test['enc_marital_status'] = pd.Series(\n",
    "    \n",
    "    le_marital_status.transform(test['marital_status'][test['marital_status'].notnull()]),\n",
    "    \n",
    "    index=test['marital_status'][test['marital_status'].notnull()].index\n",
    "               \n",
    ")\n",
    "if 'enc_marital_status' not in feature_list:\n",
    "    feature_list.append('enc_marital_status')\n",
    " \n",
    "\n",
    "test.loc[1:10, ['enc_marital_status', 'marital_status']]\n",
    "\n",
    "le_rent_or_own = CustomOrderLabelEncoder()\n",
    "\n",
    "le_rent_or_own.fit(['Own', 'Rent'])\n",
    "\n",
    " \n",
    "\n",
    "test['enc_rent_or_own'] = pd.Series(\n",
    "    \n",
    "    le_rent_or_own.transform(test['rent_or_own'][test['rent_or_own'].notnull()]),\n",
    "    \n",
    "    index=test['rent_or_own'][test['rent_or_own'].notnull()].index\n",
    "               \n",
    ")\n",
    "if 'enc_rent_or_own' not in feature_list:\n",
    "    feature_list.append('enc_rent_or_own')\n",
    " \n",
    "\n",
    "test.loc[1:10, ['enc_rent_or_own', 'rent_or_own']]\n",
    "\n",
    "le_employment_status = CustomOrderLabelEncoder()\n",
    "\n",
    "le_employment_status.fit(['Not in Labor Force', 'Employed', 'Unemployed'])\n",
    "\n",
    " \n",
    "\n",
    "test['enc_employment_status'] = pd.Series(\n",
    "    \n",
    "    le_employment_status.transform(test['employment_status'][test['employment_status'].notnull()]),\n",
    "    \n",
    "    index=test['employment_status'][test['employment_status'].notnull()].index\n",
    "               \n",
    ")\n",
    "if 'enc_employment_staus' not in feature_list:\n",
    "    feature_list.append('enc_employment_status')\n",
    " \n",
    "\n",
    "test.loc[1:10, ['enc_employment_status', 'employment_status']]\n",
    "\n",
    "test = test.drop(columns=['race_White', 'race_Black', 'race_Other or Multiple', 'race_Hispanic'], errors='ignore')\n",
    "\n",
    "test = pd.concat([test, pd.get_dummies(test.race, prefix='race')], axis=1)\n",
    "\n",
    " \n",
    "\n",
    "test.loc[4107:4111, ['race', 'race_White', 'race_Black', 'race_Other or Multiple', 'race_Hispanic']]\n",
    "column_list = list(test)\n",
    "pattern = re.compile(r'^race_(?!.*_nan$).*')\n",
    "column_list =  list(filter(pattern.match, column_list))\n",
    "for x in column_list: \n",
    "    if x not in feature_list: feature_list.append(x)\n",
    "print (column_list) \n",
    "\n",
    "test = test.drop(columns=['region_oxchjgsf', 'region_bhuqouqj', 'region_qufhixun', 'region_lrircsnp', 'region_atmpeygn', 'region_lzgpxyit',\n",
    " 'region_fpwskwrf', 'region_mlyzmhmf', 'region_dqpwygqj', 'region_kbazzjca'], errors='ignore')\n",
    "\n",
    "test = pd.concat([test, pd.get_dummies(test.hhs_geo_region, prefix='region')], axis=1)\n",
    "\n",
    " \n",
    "\n",
    "test.loc[4107:4111, ['hhs_geo_region', 'region_oxchjgsf', 'region_bhuqouqj', 'region_qufhixun', 'region_lrircsnp', 'region_atmpeygn', 'region_lzgpxyit',\n",
    " 'region_fpwskwrf', 'region_mlyzmhmf', 'region_dqpwygqj', 'region_kbazzjca']]\n",
    "column_list = list(test)\n",
    "pattern = re.compile(r'^region_(?!.*_nan$).*')\n",
    "column_list =  list(filter(pattern.match, column_list))\n",
    "for x in column_list: \n",
    "    if x not in feature_list: feature_list.append(x)\n",
    "print (column_list) \n",
    "\n",
    "test = test.drop(columns=['msa_Non-MSA', 'msa_MSA, Not Principle  City', 'msa_MSA, Principle City'], errors='ignore')\n",
    "\n",
    "test = pd.concat([test, pd.get_dummies(data.census_msa, prefix='msa')], axis=1)\n",
    "\n",
    " \n",
    "\n",
    "test.loc[4107:4111, ['census_msa', 'msa_Non-MSA', 'msa_MSA, Not Principle  City', 'msa_MSA, Principle City']]\n",
    "column_list = list(test)\n",
    "pattern = re.compile(r'^msa_(?!.*_nan$).*')\n",
    "column_list =  list(filter(pattern.match, column_list))\n",
    "for x in column_list: \n",
    "    if x not in feature_list: feature_list.append(x)\n",
    "print (column_list) \n",
    "\n",
    "test = test.drop(columns=['pxcmvdjn', 'rucpziij', 'wxleyezf', 'saaquncn', 'xicduogh', 'ldnlellj',\n",
    " 'wlfvacwt', 'nduyfdeo', 'fcxhlnwr', 'vjjrobsf', 'arjwrbjb', 'atmlpfrs',\n",
    " 'msuufmds', 'xqicxuve', 'phxvnwax', 'dotnnunm', 'mfikgejo', 'cfqqtusy',\n",
    " 'mcubkhph', 'haxffmxo', 'qnlwzans'], errors='ignore')\n",
    "\n",
    "test = pd.concat([test, pd.get_dummies(test.employment_industry, prefix='industry')], axis=1)\n",
    " \n",
    "\n",
    "test.loc[4107:4111, ['employment_industry', 'industry_pxcmvdjn', 'industry_rucpziij', 'industry_wxleyezf', 'industry_saaquncn', 'industry_xicduogh', 'industry_ldnlellj',\n",
    " 'industry_wlfvacwt', 'industry_nduyfdeo', 'industry_fcxhlnwr', 'industry_vjjrobsf', 'industry_arjwrbjb', 'industry_atmlpfrs',\n",
    " 'industry_msuufmds', 'industry_xqicxuve', 'industry_phxvnwax', 'industry_dotnnunm', 'industry_mfikgejo', 'industry_cfqqtusy',\n",
    " 'industry_mcubkhph', 'industry_haxffmxo', 'industry_qnlwzans']]\n",
    "column_list = list(test)\n",
    "pattern = re.compile(r'^industry_(?!.*_nan$).*')\n",
    "column_list =  list(filter(pattern.match, column_list))\n",
    "for x in column_list: \n",
    "    if x not in feature_list: feature_list.append(x)\n",
    "print (column_list) \n",
    "\n",
    "test = test.drop(columns=['xgwztkwe', 'xtkaffoo', 'emcorrxb', 'vlluhbov', 'xqwwgdyp', 'ccgxvspp',\n",
    " 'qxajmpny', 'kldqjyjy', 'mxkfnird', 'hfxkjkmi', 'bxpfxfdn', 'ukymxvdu',\n",
    " 'cmhcxjea', 'haliazsg', 'dlvbwzss', 'xzmlyyjv', 'oijqvulv', 'rcertsgn',\n",
    " 'tfqavkke', 'hodpvpew', 'uqqtjvyb', 'pvmttkik', 'dcjcmpih'], errors='ignore')\n",
    "\n",
    "test = pd.concat([test, pd.get_dummies(test.employment_occupation, prefix='occupation')], axis=1)\n",
    "\n",
    " \n",
    "\n",
    "test.loc[4107:4111, ['employment_occupation', 'occupation_xgwztkwe', 'occupation_xtkaffoo', 'occupation_emcorrxb', 'occupation_vlluhbov', 'occupation_xqwwgdyp', 'occupation_ccgxvspp',\n",
    " 'occupation_qxajmpny', 'occupation_kldqjyjy', 'occupation_mxkfnird', 'occupation_hfxkjkmi', 'occupation_bxpfxfdn', 'occupation_ukymxvdu',\n",
    " 'occupation_cmhcxjea', 'occupation_haliazsg', 'occupation_dlvbwzss', 'occupation_xzmlyyjv', 'occupation_oijqvulv', 'occupation_rcertsgn',\n",
    " 'occupation_tfqavkke', 'occupation_hodpvpew', 'occupation_uqqtjvyb', 'occupation_pvmttkik', 'occupation_dcjcmpih']]\n",
    "column_list = list(test)\n",
    "pattern = re.compile(r'^occupation_(?!.*_nan$).*')\n",
    "column_list =  list(filter(pattern.match, column_list))\n",
    "for x in column_list: \n",
    "    if x not in feature_list: feature_list.append(x)\n",
    "print (column_list) \n",
    "\n",
    "print(feature_list)\n",
    "\n",
    "features = test.get(feature_list)\n",
    "\n",
    "mean_features = test.dropna().mean(numeric_only=True)\n",
    "\n",
    "test_imputed_features = test.fillna(mean_features)\n",
    "\n",
    "print (test_imputed_features.count())\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "h1n1_gb = GradientBoostingClassifier(\n",
    "\n",
    "  n_estimators=300,\n",
    "\n",
    ")\n",
    "\n",
    "seas_gb = GradientBoostingClassifier(\n",
    "\n",
    "  n_estimators=300,\n",
    "\n",
    ")\n",
    "\n",
    "h1n1_rf = RandomForestClassifier(\n",
    "\n",
    "  n_estimators=300,\n",
    "\n",
    ")\n",
    "\n",
    "seas_rf = RandomForestClassifier(\n",
    "\n",
    "  n_estimators=300,\n",
    "\n",
    ")\n",
    "\n",
    "%%time\n",
    "h1n1_gb.fit(imputed_features.get(feature_list), labels['h1n1_vaccine'])\n",
    "\n",
    "%%time\n",
    "seas_gb.fit(imputed_features.get(feature_list), labels['seasonal_vaccine'])\n",
    "\n",
    "print (labels) \n",
    "\n",
    " h1n1_yhat = h1n1_gb.predict_proba(test_imputed_features.get(feature_list))\n",
    "\n",
    "seas_yhat = seas_gb.predict_proba(test_imputed_features.get(feature_list))\n",
    "\n",
    "print (seas_yhat)\n",
    "\n",
    "submission_out = pd.DataFrame(list(zip(h1n1_yhat[:, 1], seas_yhat[:, 1])), test_imputed_features['respondent_id'].values, columns=['h1n1_vaccine','seasonal_vaccine'])\n",
    "\n",
    "\n",
    "print (submission_out)\n",
    "\n",
    "submission_out.index.name = 'respondent_id'\n",
    "\n",
    "submission_out.to_csv(os.path.abspath(\"\") + '/submission-'+t.strftime('%b-%d-%Y_%H%M',t.localtime())+'.csv')\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (Intel® oneAPI 2023.1)",
   "language": "python",
   "name": "c009-intel_distribution_of_python_3_oneapi-beta05-python"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
